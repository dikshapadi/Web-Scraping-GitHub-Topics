{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74b8c744",
   "metadata": {},
   "source": [
    "# Scraping Top Repos for Top Topics on GitHub\n",
    "\n",
    "## Introduction to web scraping\n",
    "Web scraping is the process of extracting data from a specific web page. It involves making an HTTP request to a website’s server, downloading the page’s HTML and parsing it to extract the desired data.\n",
    "\n",
    "## Problem Statement \n",
    "GitHub is a code hosting platform for version control and collaboration. It lets you and others work together on projects from anywhere. This tutorial teaches you GitHub essentials like repositories, branches, commits, and pull requests.\n",
    "GitHubTopics are labels that create subject-based connections between GitHub repositories and let you explore projects by type, technology, and more.\n",
    "\n",
    "Our motive is to gather all the top repos of the top topics on GitHub, ie perform web scraping for further data analysis.\n",
    "Web scraping can be done manually, but if the process involves a large number of web pages, it is more efficient to use an automated web scraping tool like BeautifulSoup or Scrapy.\n",
    "\n",
    "Tools/Language used : Python, Beautiful Soup, Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68e6ac6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install requests --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1787f3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9804cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install beautifulsoup4 --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ecc5d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f7a97aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10b9f216",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c4e50ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_Topics():\n",
    "    topics_url = 'https://github.com/topics'\n",
    "    response = requests.get(topics_url)\n",
    "    \n",
    "    # Check response status\n",
    "    if(response.status_code!=200):\n",
    "        raise Exception('Failed to load page {}'.format(topic_url))\n",
    "    page_contents = response.text\n",
    "    doc = BeautifulSoup(page_contents,'html.parser')\n",
    "    topic_title_tags = doc.find_all('p',{'class':'f3 lh-condensed mb-0 mt-1 Link--primary'})\n",
    "    topic_desc_tags = doc.find_all('p',{'class':\"f5 color-fg-muted mb-0 mt-1\"})\n",
    "    topic_link_tags = doc.find_all('a',{'class':\"no-underline flex-1 d-flex flex-column\"})\n",
    "\n",
    "    topic_titles = []\n",
    "    topic_desc = []\n",
    "    topic_urls = []\n",
    "\n",
    "    for tag in topic_title_tags:\n",
    "        topic_titles.append(tag.text)\n",
    "    \n",
    "    for tag in topic_desc_tags:\n",
    "        topic_desc.append(tag.text.strip())\n",
    "    \n",
    "    for tag in topic_link_tags:\n",
    "        topic_urls.append('https://github.com'+tag['href'])\n",
    "    \n",
    "    Topicsdict = {'Title':topic_titles,'Description':topic_desc,'URL':topic_urls}\n",
    "    return pd.DataFrame(Topicsdict)\n",
    "\n",
    "def scrape_topic(topic_url,topic_name):\n",
    "    topic_df = get_topic_repo(get_topic_page(topic_url))\n",
    "    topic_df.to_csv(topic_name+'.csv',index = None)\n",
    "    \n",
    "def scrape_TopicsRepos():\n",
    "    print(\"Scraping top repos from GitHub\")\n",
    "    topics_df = scrape_Topics()\n",
    "    for index,row in topics_df.iterrows():\n",
    "        print('Scraping top repos for \"{}\"'.format(row['Title']))\n",
    "        scrape_topic(row['URL'],row['Title'])\n",
    "    \n",
    "def get_topic_page(topic_url):\n",
    "    # Download the page\n",
    "    response = requests.get(topic_url)\n",
    "    # Check response status\n",
    "    if(response.status_code!=200):\n",
    "        raise Exception('Failed to load page {}'.format(topic_url))\n",
    "    # Parse using beautiful soup\n",
    "    topic_doc = BeautifulSoup(response.text,'html.parser')\n",
    "    return topic_doc\n",
    "\n",
    "def parse_star_count(stars_str):\n",
    "    if(stars_str[-1]=='k'):\n",
    "        return int(float(stars_str[:-1])*1000)\n",
    "    \n",
    "def get_repo_info(h3_tag,star_tag):\n",
    "    a_tags = h3_tag.find_all('a')\n",
    "    username = a_tags[0].text.strip()\n",
    "    repo_name = a_tags[1].text.strip()\n",
    "    repo_url = 'https://github.com'+a_tags[1]['href']\n",
    "    stars = parse_star_count(star_tag.text.strip())\n",
    "    return username,repo_name,stars,repo_url\n",
    "\n",
    "def get_topic_repo(topic_doc):\n",
    "\n",
    "    repo_tags = topic_doc.find_all('h3',{'class':\"f3 color-fg-muted text-normal lh-condensed\"})\n",
    "    star_tags = topic_doc.find_all('span',{'class':'Counter js-social-count'})\n",
    "    \n",
    "    topicrepo_dict = {'username':[],'repos name':[],'stars':[],'URL':[]}\n",
    "\n",
    "    for i in range(len(repo_tags)):\n",
    "        repo_info = get_repo_info(repo_tags[i],star_tags[i])\n",
    "        topicrepo_dict['username'].append(repo_info[0])\n",
    "        topicrepo_dict['repos name'].append(repo_info[1])\n",
    "        topicrepo_dict['stars'].append(repo_info[2])   \n",
    "        topicrepo_dict['URL'].append(repo_info[3])\n",
    "        \n",
    "    return pd.DataFrame(topicrepo_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4666fe66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping top repos from GitHub\n",
      "Scraping top repos for \"3D\"\n",
      "Scraping top repos for \"Ajax\"\n",
      "Scraping top repos for \"Algorithm\"\n",
      "Scraping top repos for \"Amp\"\n",
      "Scraping top repos for \"Android\"\n",
      "Scraping top repos for \"Angular\"\n",
      "Scraping top repos for \"Ansible\"\n",
      "Scraping top repos for \"API\"\n",
      "Scraping top repos for \"Arduino\"\n",
      "Scraping top repos for \"ASP.NET\"\n",
      "Scraping top repos for \"Atom\"\n",
      "Scraping top repos for \"Awesome Lists\"\n",
      "Scraping top repos for \"Amazon Web Services\"\n",
      "Scraping top repos for \"Azure\"\n",
      "Scraping top repos for \"Babel\"\n",
      "Scraping top repos for \"Bash\"\n",
      "Scraping top repos for \"Bitcoin\"\n",
      "Scraping top repos for \"Bootstrap\"\n",
      "Scraping top repos for \"Bot\"\n",
      "Scraping top repos for \"C\"\n",
      "Scraping top repos for \"Chrome\"\n",
      "Scraping top repos for \"Chrome extension\"\n",
      "Scraping top repos for \"Command line interface\"\n",
      "Scraping top repos for \"Clojure\"\n",
      "Scraping top repos for \"Code quality\"\n",
      "Scraping top repos for \"Code review\"\n",
      "Scraping top repos for \"Compiler\"\n",
      "Scraping top repos for \"Continuous integration\"\n",
      "Scraping top repos for \"COVID-19\"\n",
      "Scraping top repos for \"C++\"\n"
     ]
    }
   ],
   "source": [
    "scrape_TopicsRepos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acdfaf5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
